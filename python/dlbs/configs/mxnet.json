{
  "parameters": {
    "mxnet.launcher": {
      "val": "${DLBS_ROOT}/scripts/launchers/mxnet.sh",
      "type": "str",
      "desc": "Path to script that launches MXNet benchmarks."
    },
    "mxnet.env": {
      "val": "",
      "type": "str",
      "desc": "An environment (a bunch of export directives) for the MXNet framework."
    },
    "mxnet.bench_path": {
      "val": "$('${DLBS_ROOT}/python' if not ${exp.docker} else '/workspace')$",
      "type": "str",
      "desc": "Python path to where mxnet_benchmarks project is located. Depends on bare metal/docker benchmarks."
    },
    "mxnet.cudnn_autotune": {
      "val": true,
      "type": "bool",
      "desc": "Enable/disable cuDNN autotune. Same as 'MXNET_CUDNN_AUTOTUNE_DEFAULT' variable (https://mxnet.incubator.apache.org/how_to/env_var.html)."
    },
    "mxnet.kv_store": {
      "val": "device",
      "type": "str",
      "var_domain": ["local", "device", "dist_sync", "dist_device_sync", "dist_async", "horovod"],
      "desc": [
        "A method to aggregate gradients (local, device, dist_sync, dist_device_sync, dist_async).",
        "See https://mxnet.incubator.apache.org/how_to/multi_devices.html for more details."
      ]
    },
    "mxnet.data_dir": {
      "val": "",
      "type": "str",
      "desc": "A data directory if real data should be used. If empty, synthetic data is used (no data ingestion pipeline)."
    },
    "mxnet.input_layout": {
      "val": "",
      "type": "str",
      "desc": [
        "Layout of an input tensor data. Now, must only be used with half precision and NGC containers for",
        "convolutional neural network - set it to NHWC"
      ]
    },
    "mxnet.model_layout": {
      "val": "",
      "type": "str",
      "desc": [
        "Layout of model tensors. Now, must only be used with half precision and NGC containers for",
        "convolutional neural network - set it to NHWC"
      ]
    },
    "mxnet.nvidia_layers": {
      "val": false,
      "type": "bool",
      "desc": "When running half precision in NGC containers, setting it to true for some models may improve performance."
    },
    "mxnet.use_dali": {
      "val": false,
      "type": "bool",
      "desc": "Use DALI for data ingestion pipeline."
    },
    "mxnet.workspace": {
      "val": 1024,
      "type": "int",
      "desc": [
        "Maximum temporary workspace allowed (MB) in convolution.This parameter has two usages. When CUDNN is not used,",
        "it determines the effective batch size of the convolution kernel. When CUDNN is used, it controls the",
        "maximum temporary storage used for tuning the best CUDNN kernel when limited_workspace strategy is used."
      ]
    },
    "mxnet.preprocess_threads": {
      "val": 4,
      "type": "int",
      "desc": [
        "Number of pre-processing threads for data ingestion pipeline when real data is used. This is used for",
        "CPU based ImageRecordIter data iterator and is not applicable to DALI pipeline."
      ]
    },
    "mxnet.prefetch_buffer": {
      "val": 10,
      "type": "int",
      "desc": "Number of batches to prefetch (buffer size)."
    },
    "mxnet.args": {
      "val": [
        "--model=${exp.model}",
        "--model_opts='${exp.model_opts}'",
        "--phase=${exp.phase}",
        "--batch_size=${exp.replica_batch}",
        "--num_warmup_batches=${exp.num_warmup_batches}",
        "--num_batches=${exp.num_batches}",
        "--gpus=${exp.gpus}",
        "--kv_store=${mxnet.kv_store}",
        "$('' if not '${exp.data_dir}' else '--data_dir=${exp.data_dir}' if ${exp.docker} is False else '--data_dir=/workspace/data')$",
        "--dtype=${exp.dtype}",
        "--preprocess_threads=${mxnet.preprocess_threads}",
        "--prefetch_buffer=${mxnet.prefetch_buffer}",
        "$('' if not '${mxnet.input_layout}' else '--input_layout=${mxnet.input_layout}')$",
        "$('' if not '${mxnet.model_layout}' else '--model_layout=${mxnet.model_layout}')$",
        "--nvidia_layers=${mxnet.nvidia_layers}",
        "--use_dali=${mxnet.use_dali}",
        "--workspace=${mxnet.workspace}"
      ],
      "type": "str",
      "desc": "Command line arguments that launcher will pass to a mxnet_benchmarks script."
    },
    "mxnet.docker_image": {
      "val": "dlbs/mxnet:18.11",
      "type": "str",
      "desc": "The name of a docker image to use for MXNet if containerized benchmark is requested."
    },
    "mxnet.docker_args": {
      "val": [
        "-i",
        "--security-opt seccomp=unconfined",
        "--pid=host",
        "--volume=${DLBS_ROOT}/python/mxnet_benchmarks:/workspace/mxnet_benchmarks",
        "$('--volume=${runtime.cuda_cache}:/workspace/cuda_cache' if '${runtime.cuda_cache}' else '')$",
        "$('--volume=${exp.data_dir}:/workspace/data' if '${exp.data_dir}' else '')$",
        "$('--volume=${monitor.pid_folder}:/workspace/tmp' if ${monitor.frequency} > 0 else '')$",
        "${exp.docker_args}",
        "${exp.docker_image}"
      ],
      "type": "str",
      "desc": "In case if containerized benchmarks, this are the docker parameters."
    },
    "mxnet.host_python_path": {
      "val": "${HOME}/projects/mxnet/python",
      "type": "str",
      "desc": "Path to a MXNET's python folder in case of a bare metal run."
    },
    "mxnet.host_libpath": {
      "val": "",
      "type": "str",
      "desc": "Basically, it's a LD_LIBRARY_PATH for MXNet in case of a bare metal run."
    },
    "mxnet.rendezvous": {
      "val": "127.0.0.1:4000",
      "type": "str",
      "desc": [
        "Experimental support  for distributed PyTorch. This parameter defines a rendezvous point (scheduler).",
        "Two formats are supported. It is either HOST:PORT or INTERFACE:HOST:PORT, for instance,",
        "127.0.0.1:55555 and ib0:127.0.0.1:55555" 
      ]
    },
    "mxnet.scheduler": {
      "val": false,
      "type": "bool",
      "desc": "For distributed benchmarks, specifies that this process needs to run scheduler."
    }
  },
  "extensions": [
    {"condition":{"exp.framework": "mxnet"}, "parameters": {"exp.framework_title": "MXNET"}},
    {
      "condition":{ "exp.framework": "mxnet", "exp.docker": true },
      "parameters": { "mxnet.env": [
        "PYTHONPATH=$('${mxnet.bench_path}:\\$PYTHONPATH'.strip(' \t:'))$",
        "${runtime.EXPORT_CUDA_CACHE_PATH}",
        "MXNET_CUDNN_AUTOTUNE_DEFAULT=$(1 if '${mxnet.cudnn_autotune}' == 'true' else 0)$",
        "MXNET_CUDA_ALLOW_TENSOR_CORE=$('TRUE' if ${exp.use_tensor_core} else 'FALSE')$"
      ]}
    },
    {
      "condition":{ "exp.framework": "mxnet", "exp.docker": false },
      "parameters": { "mxnet.env": [
        "LD_LIBRARY_PATH=$('${mxnet.host_libpath}:\\$LD_LIBRARY_PATH'.strip(' \t:'))$",
        "PYTHONPATH=$('${mxnet.host_python_path}:${mxnet.bench_path}:\\$PYTHONPATH'.strip(' \t:'))$",
        "${runtime.EXPORT_CUDA_CACHE_PATH}",
        "MXNET_CUDNN_AUTOTUNE_DEFAULT=$(1 if '${mxnet.cudnn_autotune}' == 'true' else 0)$",
        "MXNET_CUDA_ALLOW_TENSOR_CORE=$('TRUE' if ${exp.use_tensor_core} else 'FALSE')$"
      ]}
    }
  ]
}
